# ğŸ“‰ Customer Churn Prediction

**End-to-End Machine Learning Project with Deployment**

---

## ğŸ“Œ Project Overview

Customer churn is a critical business challenge where organizations aim to identify customers who are likely to stop using their services.
This project delivers an **end-to-end machine learning solution** to predict customer churn using historical customer data.

The project follows a **real-world data science workflow**, including:

* Data cleaning and preprocessing
* Exploratory data analysis (EDA)
* Feature engineering
* Model training and evaluation
* Model persistence for deployment
* Interactive web application for inference

---

## ğŸ¯ Business Objective

* Predict whether a customer will **churn (Yes / No)**
* Identify **key drivers** of customer churn
* Enable businesses to take **proactive retention actions**

---

## ğŸ–¥ï¸ Application Preview

### ğŸ”¹ Streamlit User Interface
![App UI](screenshots/app_ui.png)

### ğŸ”¹ Feature Importance
![Feature Importance](screenshots/feature_importance.png)

### ğŸ”¹ ROC Curve
![ROC Curve](screenshots/roc_curve.png)

---

## ğŸŒ Live Application (Deployment)

An interactive **Streamlit web application** demonstrates real-time churn prediction using the trained model.

ğŸ”— **Live App:**
[https://thehoodguy4587-customer-churn-prediction-app-j2dvxl.streamlit.app/](https://thehoodguy4587-customer-churn-prediction-app-j2dvxl.streamlit.app/)

### Application Features

* User-friendly interface for customer input
* Real-time churn prediction with **probability score**
* Actionable business recommendations
* Uses the **same preprocessing pipeline** as model training

---

## ğŸ—‚ï¸ Project Structure

```
Customer-churn-prediction/
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_EDA.ipynb
â”‚   â”œâ”€â”€ 02_Feature_Engineering.ipynb
â”‚   â””â”€â”€ 03_Modeling_and_Evaluation.ipynb
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ scaler.pkl
â”‚   â”œâ”€â”€ logistic_model.pkl
â”‚   â”œâ”€â”€ random_forest_model.pkl
â”‚   â””â”€â”€ feature_names.pkl
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ customer_churn.csv
â”‚   â”œâ”€â”€ X_train_scaled.npy
â”‚   â”œâ”€â”€ X_test_scaled.npy
â”‚   â”œâ”€â”€ y_train.csv
â”‚   â””â”€â”€ y_test.csv
â”‚
â”œâ”€â”€ app.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ“Š Dataset Description

The dataset contains customer-level information such as:

* Demographics (gender, senior citizen status)
* Service usage (internet service, contract type)
* Billing information (monthly charges, total charges)

### ğŸ¯ Target Variable

```
Churn = 1 â†’ Customer churned
Churn = 0 â†’ Customer retained
```

---

## ğŸ” Exploratory Data Analysis (EDA)

Key insights from EDA:

* Customers with **short tenure** have higher churn probability
* **Higher monthly charges** correlate with churn
* **Month-to-month contracts** are the strongest churn indicator
* **Electronic check** payment method shows higher churn risk

EDA includes:

* Univariate analysis
* Bivariate analysis
* Distribution plots
* Churn comparison across categorical variables

---

## ğŸ› ï¸ Feature Engineering

Performed in `02_Feature_Engineering.ipynb`

Steps:

* Converted `TotalCharges` to numeric format
* Handled missing values using **median imputation**
* One-hot encoded categorical variables (`drop_first=True`)
* Applied **StandardScaler** to numerical features
* Prevented data leakage by fitting scaler **only on training data**
* Saved feature names for consistent inference

---

## ğŸ¤– Model Building

Implemented in `03_Modeling_and_Evaluation.ipynb`

### Models Used

* Logistic Regression
* Random Forest Classifier

### Model Rationale

* **Logistic Regression:** Interpretable and strong baseline
* **Random Forest:** Captures non-linear relationships

---

## ğŸ“ˆ Model Evaluation

### Evaluation Metrics

* Accuracy
* Precision
* Recall
* F1-score
* ROC-AUC

### Key Results

* Logistic Regression outperformed Random Forest on **ROC-AUC**
* Logistic Regression provided **better interpretability**
* ROC curves used for model comparison

---

## ğŸ”‘ Feature Importance

* Logistic Regression coefficients analyzed
* Random Forest feature importance extracted

### Key Churn Drivers Identified

* Contract type
* Tenure
* Monthly charges
* Payment method

---

## ğŸ’¾ Model Persistence

Saved artifacts:

* Trained models (`.pkl`)
* Scaler object
* Feature names

These enable:

* Reuse without retraining
* Consistent preprocessing
* Seamless deployment with Streamlit

---

## ğŸš€ Tools & Technologies

* Python
* Pandas, NumPy
* Scikit-learn
* Matplotlib, Seaborn
* Joblib
* Streamlit
* Jupyter Notebook

---

## ğŸ“Œ Key Takeaways

* End-to-end ML project following **industry best practices**
* Clean separation of **EDA, feature engineering, and modeling**
* Deployment-ready pipeline
* Strong business relevance and interpretability
* Interactive web application for real-time predictions

---

## ğŸ”® Future Improvements

* Hyperparameter tuning
* Cross-validation
* Advanced models (XGBoost, LightGBM)
* SHAP-based explainability
* Model monitoring and drift detection

---

## ğŸ‘¤ Author

**Senitha Gunathilaka**
Aspiring Data Scientist

ğŸ”— LinkedIn:
[https://www.linkedin.com/in/senitha-gunathilaka-404236285/](https://www.linkedin.com/in/senitha-gunathilaka-404236285/)
